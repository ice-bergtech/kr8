{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kr8 kr8 is a configuration management tool for Kubernetes clusters, designed to generate deployable manifests for the components required to make your clusters usable. Its main function is to manipulate JSON and YAML without using a templating engine. It does this using jsonnet","title":"Home"},{"location":"#kr8","text":"kr8 is a configuration management tool for Kubernetes clusters, designed to generate deployable manifests for the components required to make your clusters usable. Its main function is to manipulate JSON and YAML without using a templating engine. It does this using jsonnet","title":"kr8"},{"location":"components/helm/","text":"Helm kr8 can render helm charts locally and inject parameters as helm values. This provides a great degree of flexibility when installing components into clusters. Taskfile An example taskfile for a helm chart might look like this: version: 2 vars: CHART_VER: v0.8.1 CHART_NAME: cert-manager tasks: fetch: desc: fetch component dependencies cmds: - rm -fr charts vendored; mkdir charts vendored # add the helm repo and fetch it locally into the charts directly - helm fetch --repo https://charts.jetstack.io --untar --untardir ./charts --version {{.CHART_VER}} {{.CHART_NAME}} - wget --quiet -N https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml -O - | grep -v ^# vendored/00cert-manager-crd.yaml generate: desc: generate cmds: - kr8-helpers clean-output - kr8-helpers yaml-install vendored/00cert-manager-crd.yaml - kr8-helpers jsonnet-render 00namespace.jsonnet - kr8-helpers helm-render {{.CHART_NAME}} Params The params.jsonnet for a helm chart directory should include the helm values you want to use. Here's an example: { release_name: 'cert-manager', namespace: 'cert-manager', kubecfg_gc_enable: true, kubecfg_update_args: '--validate=false', helm_values: { webhook: { enabled: false }, // this is a value for the helm chart }, } Values file A values file is a required file for a helm component. The name of the file must be componentname-values.jsonnet (for example: cert-manager-values.jsonnet). It's content would be something like this: local config = std.extVar('kr8'); if 'helm_values' in config then config.helm_values else {} You can also optionally set the values for the helm chart in here, this would look something like this: { replicaCount: 2 } Patches There are certain situations where a configuration option is not available for a helm chart, for example, you might want to add an argument that hasn't quite made it into the helm chart yet, or add something like pod affinity where it isn't actually a value option in a helm chart. kr8 helps you in this situation by providing a mechanism to patch a helm chart. You need to use the helm-render-with-patch helper and provide a patches.jsonnet in the component directory. Here's an example patches.jsonnet for external-dns local apptio = import 'apptio.libsonnet'; local helpers = import 'helpers.libsonnet'; // some helper functions local kube = import 'kube.libsonnet'; local config = std.extVar('kr8'); // config is all the config from params.jsonnet // remove Secret objects and add a namespace [ for object in helpers.list( // object list is converted to hash of named objects, then they can be modified by name helpers.named(helpers.helmInput) + { ['Deployment/' + config.release_name]+: helpers.patchContainer({ // Injects an extra arg, which wasn't originally in the helm chart [if std.objectHas(config,'assumeRoleArn') then 'args']+: ['--aws-assume-role='+config.assumeRoleArn], }), }, ) ]","title":"Helm"},{"location":"components/helm/#helm","text":"kr8 can render helm charts locally and inject parameters as helm values. This provides a great degree of flexibility when installing components into clusters.","title":"Helm"},{"location":"components/helm/#taskfile","text":"An example taskfile for a helm chart might look like this: version: 2 vars: CHART_VER: v0.8.1 CHART_NAME: cert-manager tasks: fetch: desc: fetch component dependencies cmds: - rm -fr charts vendored; mkdir charts vendored # add the helm repo and fetch it locally into the charts directly - helm fetch --repo https://charts.jetstack.io --untar --untardir ./charts --version {{.CHART_VER}} {{.CHART_NAME}} - wget --quiet -N https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml -O - | grep -v ^# vendored/00cert-manager-crd.yaml generate: desc: generate cmds: - kr8-helpers clean-output - kr8-helpers yaml-install vendored/00cert-manager-crd.yaml - kr8-helpers jsonnet-render 00namespace.jsonnet - kr8-helpers helm-render {{.CHART_NAME}}","title":"Taskfile"},{"location":"components/helm/#params","text":"The params.jsonnet for a helm chart directory should include the helm values you want to use. Here's an example: { release_name: 'cert-manager', namespace: 'cert-manager', kubecfg_gc_enable: true, kubecfg_update_args: '--validate=false', helm_values: { webhook: { enabled: false }, // this is a value for the helm chart }, }","title":"Params"},{"location":"components/helm/#values-file","text":"A values file is a required file for a helm component. The name of the file must be componentname-values.jsonnet (for example: cert-manager-values.jsonnet). It's content would be something like this: local config = std.extVar('kr8'); if 'helm_values' in config then config.helm_values else {} You can also optionally set the values for the helm chart in here, this would look something like this: { replicaCount: 2 }","title":"Values file"},{"location":"components/helm/#patches","text":"There are certain situations where a configuration option is not available for a helm chart, for example, you might want to add an argument that hasn't quite made it into the helm chart yet, or add something like pod affinity where it isn't actually a value option in a helm chart. kr8 helps you in this situation by providing a mechanism to patch a helm chart. You need to use the helm-render-with-patch helper and provide a patches.jsonnet in the component directory. Here's an example patches.jsonnet for external-dns local apptio = import 'apptio.libsonnet'; local helpers = import 'helpers.libsonnet'; // some helper functions local kube = import 'kube.libsonnet'; local config = std.extVar('kr8'); // config is all the config from params.jsonnet // remove Secret objects and add a namespace [ for object in helpers.list( // object list is converted to hash of named objects, then they can be modified by name helpers.named(helpers.helmInput) + { ['Deployment/' + config.release_name]+: helpers.patchContainer({ // Injects an extra arg, which wasn't originally in the helm chart [if std.objectHas(config,'assumeRoleArn') then 'args']+: ['--aws-assume-role='+config.assumeRoleArn], }), }, ) ]","title":"Patches"},{"location":"components/jk/","text":"jk","title":"Jk"},{"location":"components/jk/#jk","text":"","title":"jk"},{"location":"components/jsonnet/","text":"Jsonnet Component A very simple component might just be a few lines of jsonnet. Consider the situation whereby you might have two clusters, one in AWS and one in DigitalOcean. You need to set a default storageclass. You could do this with jsonnet. Your jsonnet component would look like this: components/storageclasses \u251c\u2500\u2500 Taskfile.yml \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 storageclasses.jsonnet Taskfile The taskfile for a component like would look like this: version: 2 tasks: fetch: desc: fetch component dependencies generate: desc: generate cmds: - kr8-helpers clean-output - kr8-helpers jsonnet-render storageclasses.jsonnet Notice we still add a fetch task which is an empty command Params As a reminder, every component requires a params file. We need to set a namespace for the component, even though it's a cluster level resource - namespace is a required paramater for kr8 { namespace: 'kube-system', release_name: 'storageclasses', } Jsonnet Manifest Your jsonnet manifest looks like this: local config = std.extVar('kr8'); # imports the config from params.jsonnet local kr8_cluster = std.extVar('kr8_cluster'); # a jsonnet external variable from kr8 that gets cluster values and data # a jsonnet function for creating a storageclass local StorageClass(name, type, default=false) = { apiVersion: 'storage.k8s.io/v1', kind: 'StorageClass', metadata: { name: name, annotations: { 'storageclass.kubernetes.io/is-default-class': if default then 'true' else 'false', }, }, parameters: { type: type, }, }; # check the cluster configuration for a type, if it's AWS make a gp2 type storageclass if kr8_cluster.cluster_type == 'aws' then kube.objectValues( { // default gp2 storage class, not tied to a zone ebs_gp2: StorageClass('gp2', 'gp2', true) {}, } ) else [] # don't make a storageclass if it's not AWS","title":"Jsonnet"},{"location":"components/jsonnet/#jsonnet-component","text":"A very simple component might just be a few lines of jsonnet. Consider the situation whereby you might have two clusters, one in AWS and one in DigitalOcean. You need to set a default storageclass. You could do this with jsonnet. Your jsonnet component would look like this: components/storageclasses \u251c\u2500\u2500 Taskfile.yml \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 storageclasses.jsonnet","title":"Jsonnet Component"},{"location":"components/jsonnet/#taskfile","text":"The taskfile for a component like would look like this: version: 2 tasks: fetch: desc: fetch component dependencies generate: desc: generate cmds: - kr8-helpers clean-output - kr8-helpers jsonnet-render storageclasses.jsonnet Notice we still add a fetch task which is an empty command","title":"Taskfile"},{"location":"components/jsonnet/#params","text":"As a reminder, every component requires a params file. We need to set a namespace for the component, even though it's a cluster level resource - namespace is a required paramater for kr8 { namespace: 'kube-system', release_name: 'storageclasses', }","title":"Params"},{"location":"components/jsonnet/#jsonnet-manifest","text":"Your jsonnet manifest looks like this: local config = std.extVar('kr8'); # imports the config from params.jsonnet local kr8_cluster = std.extVar('kr8_cluster'); # a jsonnet external variable from kr8 that gets cluster values and data # a jsonnet function for creating a storageclass local StorageClass(name, type, default=false) = { apiVersion: 'storage.k8s.io/v1', kind: 'StorageClass', metadata: { name: name, annotations: { 'storageclass.kubernetes.io/is-default-class': if default then 'true' else 'false', }, }, parameters: { type: type, }, }; # check the cluster configuration for a type, if it's AWS make a gp2 type storageclass if kr8_cluster.cluster_type == 'aws' then kube.objectValues( { // default gp2 storage class, not tied to a zone ebs_gp2: StorageClass('gp2', 'gp2', true) {}, } ) else [] # don't make a storageclass if it's not AWS","title":"Jsonnet Manifest"},{"location":"components/yaml/","text":"YAML Component kr8 can use a static k8s manifest as a source input. You can then manipulate the structure of that YAML using Jsonnet. kr8 takes care of the heavy lifting for you. Taskfile You'll need a taskfile that downloads the original manifests for you in the fetch task. Here's an example: version: 2 # Download the example manifests for the metrics server. # This creates a directory, vendored which contains the manifests tasks: fetch: desc: fetch component dependencies cmds: - rm -rf vendored - mkdir -p vendored sources - git clone --depth=1 https://github.com/kubernetes-incubator/metrics-server sources/metrics-server - cp -a sources/metrics-server/deploy/1.8+/*.yaml ./vendored/ - git add ./vendored - rm -rf sources generate: desc: generate cmds: - kr8-helpers clean-output - find vendored -type f -name *.yaml -exec kr8-helpers yaml-install '{}' \\; # install all the manifests in the vendored directory directly, without changing then # use the metrics-server-deployment.yaml as the input to the jsonnet file - KR8_JSONNET_ARGS='--ext-str-file inputMetricsServerDeploy=vendored/metrics-server-deployment.yaml' kr8-helpers jsonnet-render metrics-server-deployment.jsonnet Jsonnet You'll notice in the taskfile above that this line: KR8_JSONNET_ARGS='--ext-str-file inputMetricsServerDeploy=vendored/metrics-server-deployment.yaml' kr8-helpers jsonnet-render metrics-server-deployment.jsonnet References one of the files in vendored. This give us the ability to modify this file. Here's how the jsonnet looks: local helpers = import 'helpers.libsonnet'; local parseYaml = std.native('parseYaml'); # this must match the `ext-str-file` value in the taskfile # it imports those values with the variable name deployment local deployment = parseYaml(std.extVar('inputMetricsServerDeploy')); local args = [ --kubelet-insecure-tls , --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname , ] [ # drop all the secrets if they're found, we don't want to check them into git if object.kind == 'Secret' then {} else object for object in helpers.list( helpers.named(deployment) + { # grab kind deployment with name metrics-server, and add some more args ['Deployment/kube-system/metrics-server']+: helpers.patchContainerNamed( metrics-server , { args +: args, } ), } ) ]","title":"YAML"},{"location":"components/yaml/#yaml-component","text":"kr8 can use a static k8s manifest as a source input. You can then manipulate the structure of that YAML using Jsonnet. kr8 takes care of the heavy lifting for you.","title":"YAML Component"},{"location":"components/yaml/#taskfile","text":"You'll need a taskfile that downloads the original manifests for you in the fetch task. Here's an example: version: 2 # Download the example manifests for the metrics server. # This creates a directory, vendored which contains the manifests tasks: fetch: desc: fetch component dependencies cmds: - rm -rf vendored - mkdir -p vendored sources - git clone --depth=1 https://github.com/kubernetes-incubator/metrics-server sources/metrics-server - cp -a sources/metrics-server/deploy/1.8+/*.yaml ./vendored/ - git add ./vendored - rm -rf sources generate: desc: generate cmds: - kr8-helpers clean-output - find vendored -type f -name *.yaml -exec kr8-helpers yaml-install '{}' \\; # install all the manifests in the vendored directory directly, without changing then # use the metrics-server-deployment.yaml as the input to the jsonnet file - KR8_JSONNET_ARGS='--ext-str-file inputMetricsServerDeploy=vendored/metrics-server-deployment.yaml' kr8-helpers jsonnet-render metrics-server-deployment.jsonnet","title":"Taskfile"},{"location":"components/yaml/#jsonnet","text":"You'll notice in the taskfile above that this line: KR8_JSONNET_ARGS='--ext-str-file inputMetricsServerDeploy=vendored/metrics-server-deployment.yaml' kr8-helpers jsonnet-render metrics-server-deployment.jsonnet References one of the files in vendored. This give us the ability to modify this file. Here's how the jsonnet looks: local helpers = import 'helpers.libsonnet'; local parseYaml = std.native('parseYaml'); # this must match the `ext-str-file` value in the taskfile # it imports those values with the variable name deployment local deployment = parseYaml(std.extVar('inputMetricsServerDeploy')); local args = [ --kubelet-insecure-tls , --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname , ] [ # drop all the secrets if they're found, we don't want to check them into git if object.kind == 'Secret' then {} else object for object in helpers.list( helpers.named(deployment) + { # grab kind deployment with name metrics-server, and add some more args ['Deployment/kube-system/metrics-server']+: helpers.patchContainerNamed( metrics-server , { args +: args, } ), } ) ]","title":"Jsonnet"},{"location":"concepts/clusters/","text":"Clusters A cluster is a manageable cluster in kr8. Clusters are defined in a hierarchical system which is loosely inspired by Hiera from the Puppet ecosystem. An example definition for clusters might look like this: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet The clusters are given names and then grouped together inside a directory tree. There are two jsonnet files you'll notice here: cluster.jsonnet - this defines a named cluster, kr8 will stop going down through the directory tree when it finds this file params.jsonnet - this is a file which can have components and parameters defined for clustes lower down in the hierarchy. We'll go into more detail about this shortly. Components in clusters Adding a component to a cluster involves add a component key to the _components key inside either the cluster.jsonnet or the params.jsonnet . Here's an example: _components+: { sealed_secrets: { path: 'components/sealed_secrets' }, }, Notice we're using the jsonnet + operator to make sure we're appending this to the list of components for that cluster, which will ensure the inheritance system works Cluster parameters Once you've initialized a component for a cluster, you can then start to override parameters for that component. You do this by simply defining a jsonnet key with the named parameters in it. Here's an example: external_dns+: { provider: 'cloudflare', txtPrefix: 'dev1', txtOwnerId: 'dev1-', domainFilters: [ 'example.com', ], tolerateMasters: false, }, Hierarchy System The hierarchy system is a very powerful part or kr8. It allows you to remove duplication of parameter and component definitions. Take the previous cluster layout as an example: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet You can use the hierarchy system to ensure you have components installed in all clusters. Let's assume we want to make sure that we want to install the sealed_secrets component in all our clusters. We'd put it in this file: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet ---- place component here \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet Alongside that, let's assume all our production clusters are using the same external_dns domain name. We can define that like so: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet --- place external_dns configuration here \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet kr8 will look for the smallest unit of configuration, so if you want one cluster to be slightly different inside a hierarchy unit, you can continue to override components and parameters inside a clusters' cluster.jsonnet file.","title":"Clusters"},{"location":"concepts/clusters/#clusters","text":"A cluster is a manageable cluster in kr8. Clusters are defined in a hierarchical system which is loosely inspired by Hiera from the Puppet ecosystem. An example definition for clusters might look like this: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet The clusters are given names and then grouped together inside a directory tree. There are two jsonnet files you'll notice here: cluster.jsonnet - this defines a named cluster, kr8 will stop going down through the directory tree when it finds this file params.jsonnet - this is a file which can have components and parameters defined for clustes lower down in the hierarchy. We'll go into more detail about this shortly.","title":"Clusters"},{"location":"concepts/clusters/#components-in-clusters","text":"Adding a component to a cluster involves add a component key to the _components key inside either the cluster.jsonnet or the params.jsonnet . Here's an example: _components+: { sealed_secrets: { path: 'components/sealed_secrets' }, }, Notice we're using the jsonnet + operator to make sure we're appending this to the list of components for that cluster, which will ensure the inheritance system works","title":"Components in clusters"},{"location":"concepts/clusters/#cluster-parameters","text":"Once you've initialized a component for a cluster, you can then start to override parameters for that component. You do this by simply defining a jsonnet key with the named parameters in it. Here's an example: external_dns+: { provider: 'cloudflare', txtPrefix: 'dev1', txtOwnerId: 'dev1-', domainFilters: [ 'example.com', ], tolerateMasters: false, },","title":"Cluster parameters"},{"location":"concepts/clusters/#hierarchy-system","text":"The hierarchy system is a very powerful part or kr8. It allows you to remove duplication of parameter and component definitions. Take the previous cluster layout as an example: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet You can use the hierarchy system to ensure you have components installed in all clusters. Let's assume we want to make sure that we want to install the sealed_secrets component in all our clusters. We'd put it in this file: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet ---- place component here \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet Alongside that, let's assume all our production clusters are using the same external_dns domain name. We can define that like so: clusters \u251c\u2500\u2500 development \u2502 \u2514\u2500\u2500 dev1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u251c\u2500\u2500 params.jsonnet \u2514\u2500\u2500 production \u251c\u2500\u2500 params.jsonnet --- place external_dns configuration here \u251c\u2500\u2500 prod1 \u2502 \u2514\u2500\u2500 cluster.jsonnet \u2514\u2500\u2500 prod2 \u2514\u2500\u2500 cluster.jsonnet kr8 will look for the smallest unit of configuration, so if you want one cluster to be slightly different inside a hierarchy unit, you can continue to override components and parameters inside a clusters' cluster.jsonnet file.","title":"Hierarchy System"},{"location":"concepts/components/","text":"Components A component is a deployable unit that you wish to install to multiple clusters. Your component might begin life before kr8 in one of a few ways: a Helm Chart a static YAML manifest some Jsonnet but they all have something in common - you need to deploy it to multiple clusters with slight differences in configuration. Taskfile This task file lives inside the component directory. It should contain two tasks: fetch - a manually run task which downloads all the components' dependencies (for example, helm chart or static manifest) generate - this is the task that's run when kr8 generates the manifest for the cluster These tasks will be highly dependent on the particular component - for example, a component using a helm chart will generally have a different set of fetch and generate tasks to a component using a static manifest. An example Taskfile might look like this: version: 2 vars: KR8_COMPONENT: kubemonkey tasks: fetch: desc: fetch component kubemonkey cmds: - curl -L https://github.com/asobti/kube-monkey/tarball/master kubemonkey.tar.gz # download the local helm chart from the git repo - tar --strip-components=2 -xzvf kubemonkey.tar.gz asobti-kube-monkey-{{.GIT_COMMIT}}/helm # extract it - mv kubemonkey charts # place it in a charts directory - rm -fr *.tar.gz # remove the tar.gz from the repo vars: GIT_COMMIT: sh: curl -s https://api.github.com/repos/asobti/kube-monkey/commits/master | jq .sha -r | xargs git rev-parse --short generate: desc: generate cmds: - KR8_COMPONENT={{.KR8_COMPONENT}} kr8-helpers clean-output # clean the tmp directories each time we generate - KR8_COMPONENT={{.KR8_COMPONENT}} kr8-helpers helm-render-with-patch {{.KR8_COMPONENT}} patches.jsonnet # our generate command, which in this case is a helm-render with some patches in a jsonnet file Params kr8's most useful feature is the ability to configure parameters for a specific cluster. It does that by specifying a params.jsonnet in each component. There are some required parameters which always must exist. They are: namespace : the namespace the component should be installed in release_name : analogous to a helm release - what the component should be called when it's installed into a cluster kubecfg_gc_enable : whether this component should be garbage collected when the deployer script cleans up this component (generally should be false for important system components like namespaces) Without these parameters, components will not install a function. A barebones params.jsonnet would look like this: { namespace: 'kubemonkey', release_name: 'kubemonkey', kubecfg_gc_enable: true, } Cluster specific parameters Once you start to install components into clusters, you'll want to specify parameters of your own. These are done in the params.jsonnet and you can either specify a default, or make it mandatory using jsonnet's error . Here's an more detailed example: { namespace: 'kubemonkey', release_name: 'kubemonkey', kubecfg_gc_enable: true, dry_run: false, run_hour: error 'Must specify a time for kubemonkey to run' }","title":"Components"},{"location":"concepts/components/#components","text":"A component is a deployable unit that you wish to install to multiple clusters. Your component might begin life before kr8 in one of a few ways: a Helm Chart a static YAML manifest some Jsonnet but they all have something in common - you need to deploy it to multiple clusters with slight differences in configuration.","title":"Components"},{"location":"concepts/components/#taskfile","text":"This task file lives inside the component directory. It should contain two tasks: fetch - a manually run task which downloads all the components' dependencies (for example, helm chart or static manifest) generate - this is the task that's run when kr8 generates the manifest for the cluster These tasks will be highly dependent on the particular component - for example, a component using a helm chart will generally have a different set of fetch and generate tasks to a component using a static manifest. An example Taskfile might look like this: version: 2 vars: KR8_COMPONENT: kubemonkey tasks: fetch: desc: fetch component kubemonkey cmds: - curl -L https://github.com/asobti/kube-monkey/tarball/master kubemonkey.tar.gz # download the local helm chart from the git repo - tar --strip-components=2 -xzvf kubemonkey.tar.gz asobti-kube-monkey-{{.GIT_COMMIT}}/helm # extract it - mv kubemonkey charts # place it in a charts directory - rm -fr *.tar.gz # remove the tar.gz from the repo vars: GIT_COMMIT: sh: curl -s https://api.github.com/repos/asobti/kube-monkey/commits/master | jq .sha -r | xargs git rev-parse --short generate: desc: generate cmds: - KR8_COMPONENT={{.KR8_COMPONENT}} kr8-helpers clean-output # clean the tmp directories each time we generate - KR8_COMPONENT={{.KR8_COMPONENT}} kr8-helpers helm-render-with-patch {{.KR8_COMPONENT}} patches.jsonnet # our generate command, which in this case is a helm-render with some patches in a jsonnet file","title":"Taskfile"},{"location":"concepts/components/#params","text":"kr8's most useful feature is the ability to configure parameters for a specific cluster. It does that by specifying a params.jsonnet in each component. There are some required parameters which always must exist. They are: namespace : the namespace the component should be installed in release_name : analogous to a helm release - what the component should be called when it's installed into a cluster kubecfg_gc_enable : whether this component should be garbage collected when the deployer script cleans up this component (generally should be false for important system components like namespaces) Without these parameters, components will not install a function. A barebones params.jsonnet would look like this: { namespace: 'kubemonkey', release_name: 'kubemonkey', kubecfg_gc_enable: true, }","title":"Params"},{"location":"concepts/components/#cluster-specific-parameters","text":"Once you start to install components into clusters, you'll want to specify parameters of your own. These are done in the params.jsonnet and you can either specify a default, or make it mandatory using jsonnet's error . Here's an more detailed example: { namespace: 'kubemonkey', release_name: 'kubemonkey', kubecfg_gc_enable: true, dry_run: false, run_hour: error 'Must specify a time for kubemonkey to run' }","title":"Cluster specific parameters"},{"location":"concepts/helpers/","text":"Helpers kr8-helpers is a set of scripts that wraps around the kr8 command for rendering components. The different types of components have different helps. You should ensure the kr8-helpers scripts are available in your $PATH . You can find them here clean-output This helper cleans the generated directory and the metadata directory for each component. It should generally be the first helper you run as part of your component Taskfile helm-render Render a helm chart using helm template . This allows you to install helm charts as components with kr8. For more information, see the helm component section Example: kr8-helpers helm-render {{.CHART_NAME}} helm-render-with-patch Similar to helm-render except you can also patch the helm chart and add options and configuration that might not be exposed as a helm values.yaml . This helper will look for a patches.jsonnet inside the component directory. For more information, see the helm component section Example: kr8-helpers helm-render-with-patch {{.CHART_NAME}} patches.jsonnet yaml-install The simplest helper, this just copies a specified yaml file for the component into the generated directory. It also cleans the yaml file of any unnecessary whitespace using the helmclean command in kr8 Example: kr8-helpers yaml-install vendored/01_crd.yaml jsonnet-render Render a jsonnet file. If you're starting a component without any source manifests or helm chart, or using something like the prometheus-operator this would be what you'd use. Example: kr8-helpers jsonnet-render secrets.jsonnet jk-render jk is a tool which allows you to write configuration as actual code. You can use jk to render a component: Example: kr8-helpers jk-render nginx.js","title":"Helpers"},{"location":"concepts/helpers/#helpers","text":"kr8-helpers is a set of scripts that wraps around the kr8 command for rendering components. The different types of components have different helps. You should ensure the kr8-helpers scripts are available in your $PATH . You can find them here","title":"Helpers"},{"location":"concepts/helpers/#clean-output","text":"This helper cleans the generated directory and the metadata directory for each component. It should generally be the first helper you run as part of your component Taskfile","title":"clean-output"},{"location":"concepts/helpers/#helm-render","text":"Render a helm chart using helm template . This allows you to install helm charts as components with kr8. For more information, see the helm component section Example: kr8-helpers helm-render {{.CHART_NAME}}","title":"helm-render"},{"location":"concepts/helpers/#helm-render-with-patch","text":"Similar to helm-render except you can also patch the helm chart and add options and configuration that might not be exposed as a helm values.yaml . This helper will look for a patches.jsonnet inside the component directory. For more information, see the helm component section Example: kr8-helpers helm-render-with-patch {{.CHART_NAME}} patches.jsonnet","title":"helm-render-with-patch"},{"location":"concepts/helpers/#yaml-install","text":"The simplest helper, this just copies a specified yaml file for the component into the generated directory. It also cleans the yaml file of any unnecessary whitespace using the helmclean command in kr8 Example: kr8-helpers yaml-install vendored/01_crd.yaml","title":"yaml-install"},{"location":"concepts/helpers/#jsonnet-render","text":"Render a jsonnet file. If you're starting a component without any source manifests or helm chart, or using something like the prometheus-operator this would be what you'd use. Example: kr8-helpers jsonnet-render secrets.jsonnet","title":"jsonnet-render"},{"location":"concepts/helpers/#jk-render","text":"jk is a tool which allows you to write configuration as actual code. You can use jk to render a component: Example: kr8-helpers jk-render nginx.js","title":"jk-render"},{"location":"concepts/overview/","text":"Concepts kr8 has two main concepts you should be aware of before you get started: components clusters The relationship between components and clusters are simple: components are installed on clusters. You will have components that are installed on all clusters, and some components will only be installed on some clusters. Components can be declared multiple times within a cluster, as long as they are named distinctly. Clusters are unique and singular. They have a name which is specified via the directory structure under clusters Read more about components and clusters","title":"Overview"},{"location":"concepts/overview/#concepts","text":"kr8 has two main concepts you should be aware of before you get started: components clusters The relationship between components and clusters are simple: components are installed on clusters. You will have components that are installed on all clusters, and some components will only be installed on some clusters. Components can be declared multiple times within a cluster, as long as they are named distinctly. Clusters are unique and singular. They have a name which is specified via the directory structure under clusters Read more about components and clusters","title":"Concepts"},{"location":"installation/dependencies/","text":"Dependencies The kr8 binary has a single job: generate manifests. In order to ensure you can create components and install them, you'll need some dependencies. go-task Each component in a kr8 configuration directory must have a Taskfile . To generate the component, you'll need to install go-task. See the go-task installation instructions for more information","title":"Dependencies"},{"location":"installation/dependencies/#dependencies","text":"The kr8 binary has a single job: generate manifests. In order to ensure you can create components and install them, you'll need some dependencies.","title":"Dependencies"},{"location":"installation/dependencies/#go-task","text":"Each component in a kr8 configuration directory must have a Taskfile . To generate the component, you'll need to install go-task. See the go-task installation instructions for more information","title":"go-task"},{"location":"installation/linux/","text":"Linux kr8 is a Go binary, which means you can simply download it from the Github releases page RPM and DEB packages are also generated for each release Dependencies Installation with Linux does not pull in the additional dependencies. Please see the dependencies page for more details.","title":"Linux"},{"location":"installation/linux/#linux","text":"kr8 is a Go binary, which means you can simply download it from the Github releases page RPM and DEB packages are also generated for each release","title":"Linux"},{"location":"installation/linux/#dependencies","text":"Installation with Linux does not pull in the additional dependencies. Please see the dependencies page for more details.","title":"Dependencies"},{"location":"installation/osx/","text":"OS X Homebrew The easiest way to get started with kr8 is to use the homebrew tap. This will install all the tools kr8 depends on for you. brew tap apptio/tap brew install kr8 Manually kr8 is a Go binary, which means you can simply download it from the Github releases page If you choose to install kr8 manually, you'll need to install the dependencies. Please see the dependencies page for more details","title":"OSX"},{"location":"installation/osx/#os-x","text":"","title":"OS X"},{"location":"installation/osx/#homebrew","text":"The easiest way to get started with kr8 is to use the homebrew tap. This will install all the tools kr8 depends on for you. brew tap apptio/tap brew install kr8","title":"Homebrew"},{"location":"installation/osx/#manually","text":"kr8 is a Go binary, which means you can simply download it from the Github releases page If you choose to install kr8 manually, you'll need to install the dependencies. Please see the dependencies page for more details","title":"Manually"}]}